{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "undefined-progressive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n",
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This set of functions help the users resize\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import detectron2\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine.defaults import DefaultPredictor\n",
    "\n",
    "import labelme\n",
    "from labelme import LabelFile\n",
    "from labelme import utils\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "heavy-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_dict(directory, img_height, img_width):\n",
    "    \"\"\"\n",
    "    This is the wrapper function that converts all json files in the designated \n",
    "    directory into requred image height and width, and store the dataset as\n",
    "    a Detectron2 input type.\n",
    "    Inputs:\n",
    "        - directory: the directory path where all training .json files are located\n",
    "        - img_heght: the expected image height after conversion in unit of pixel\n",
    "        - img_width: the expected image width after conversion in unit of pixel\n",
    "    Outputs:\n",
    "        - dataset_dict: list[{dictionary1}, {dictionary2},...]. Each dictionary\n",
    "                        contains segmentation information for each image.\n",
    "        - imgs: list[nparray1, nparray2,...]. Each np array signifies an image.\n",
    "        - polygonlist: list[list[]]\n",
    "    \"\"\"\n",
    "    # Load only .json files in the directory\n",
    "    path = directory\n",
    "    valid_filetype = [\".json\"]\n",
    "    imgs = []\n",
    "    polygon_list = []\n",
    "    dataset_dict = []\n",
    "    img_num = 0\n",
    "    for file in os.listdir(path):\n",
    "        filename = os.path.splitext(file)[0] # filename without extension\n",
    "        ext = os.path.splitext(file)[1] # find the extension of the file\n",
    "        if ext.lower() not in valid_filetype:\n",
    "            continue\n",
    "        img, polygons = json_to_arrs(path+file)\n",
    "        new_img, new_polygons = img_mask_rescale(img, polygons, img_height, img_width)\n",
    "        img2save = Image.fromarray(new_img)\n",
    "        img2save.save(filename+\".png\")\n",
    "        reshaped_polygons, bb_boxes = polygon_arr_to_list(new_polygons)\n",
    "        img_dict = to_dict(path, file, img_num, img_height, img_width, reshaped_polygons, bb_boxes)\n",
    "        dataset_dict.append(img_dict)\n",
    "        # Append to global lists for secondary outputs\n",
    "        imgs.append(new_img)\n",
    "        polygon_list.append(new_polygons)\n",
    "        img_num = img_num+1\n",
    "    return dataset_dict, imgs, polygon_list #imgs,polygon_list  # list[{image1},{image2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "chemical-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_json_to_dict():\n",
    "    \"\"\"\n",
    "    Test json_to_dict()\n",
    "    \"\"\"\n",
    "    dictionary, imgs, polygon_list = json_to_dict(\"test_data/test_json/\", 200, 500)\n",
    "    assert isinstance(dictionary, list), \"Unexpected output type\"\n",
    "    assert isinstance(dictionary[0], dict), \"Unexpected output type\"\n",
    "    assert len(imgs)==len(polygon_list), \"Image counts doesn't match polygon counts\"\n",
    "    return\n",
    "\n",
    "def test_show_img_and_mask():\n",
    "    \"\"\"\n",
    "    Test show_img_and_mask()\n",
    "    \"\"\"\n",
    "    imgs = [np.array([[1,1,1],[1,1,1]]),np.array([[2,2,2],[2,2,2]]),np.array([[3,3,3],[3,3,3]])]\n",
    "    polygon_list = [[np.array([[1,1],[1,1]]),np.array([[2,2],[2,2]])],[],[]]\n",
    "    assert len(imgs)==len(polygon_list), \"Image counts doesn't match polygon counts\"\n",
    "    return\n",
    "\n",
    "def test_json_to_arrs():\n",
    "    \"\"\"\n",
    "    Test test_json_to_arrs()\n",
    "    \"\"\"\n",
    "    img, poly_for_single_img = json_to_arrs(\"test_data/test_json/test_json1.json\")\n",
    "    if len(poly_for_single_img[0]) != 0:\n",
    "        assert len(poly_for_single_img[0][0]) == 2, \"Coordinates have the wrong shape\"\n",
    "    return\n",
    "\n",
    "def test_polygon_arr_to_list():\n",
    "    \"\"\"\n",
    "    Test polygon_arr_to_list()\n",
    "    \"\"\"\n",
    "    test_poly = [np.array([[1,1],[2,2],[3,3]]), np.array([[1,1],[2,2],[3,3]])]\n",
    "    new_poly, box = polygon_arr_to_list(test_poly)\n",
    "    assert len(new_poly[0]) == test_poly[0].shape[0]*test_poly[0].shape[1]\n",
    "    return\n",
    "\n",
    "def test_img_mask_rescale():\n",
    "    \"\"\"\n",
    "    Test img_mask_rescale()\n",
    "    \"\"\"\n",
    "    # Test with empty mask array\n",
    "    new_img, new_poly = img_mask_rescale(imgs[0], np.array([]), 300, 200)\n",
    "    assert not new_poly == True, \"Unexpected results for zero mask scenario\"\n",
    "    return\n",
    "def test_to_dict():\n",
    "    \"\"\"\n",
    "    Test test_to_dict()\n",
    "    \"\"\"\n",
    "    test_dictionary = to_dict(\"test_data/test_json/\",\"test_json1.json\",\n",
    "                     1,234,567,[[1, 1, 2, 2, 3, 3], [4, 4, 5, 5, 6, 6]],\n",
    "                     [[1, 1, 3, 3], [4, 4, 6, 6]])\n",
    "    for key in ['file_name', 'image_id', 'height', 'width', 'annotations']:\n",
    "        assert key in dictionary.keys(), \"Missing dictionary keys\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "liable-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = to_dict(\"test_data/test_json/\",\"test_json1.json\",\n",
    "                     1,234,567,[[1, 1, 2, 2, 3, 3], [4, 4, 5, 5, 6, 6]],\n",
    "                     [[1, 1, 3, 3], [4, 4, 6, 6]])\n",
    "for key in ['file_name', 'image_id', 'height', 'width', 'annotations']:\n",
    "    assert key in dictionary.keys()\n",
    "#print(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "intellectual-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, poly = json_to_arrs(\"test_data/test_json/test_json1.json\")\n",
    "poly[0].shape\n",
    "type(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "adopted-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon = poly[0]\n",
    "reshaped_poly = polygon.reshape(1,polygon.shape[0]*polygon.shape[1]).tolist()[0]   \n",
    "len(reshaped_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "varied-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 1, 3, 3], [4, 4, 6, 6]]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poly = [np.array([[1,1],[2,2],[3,3]]), np.array([[4,4],[5,5],[6,6]])]\n",
    "print(test_poly[0].shape)\n",
    "p,b = polygon_arr_to_list(test_poly)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "prime-tradition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p,b = polygon_arr_to_list(poly)\n",
    "type(p[0])\n",
    "#p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "varying-harmony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imgs = [np.array([[1,1,1],[1,1,1]]),np.array([[2,2,2],[2,2,2]]),np.array([[3,3,3],[3,3,3]])]\n",
    "#polygon_list = [[np.array([[1,1],[1,1]]),np.array([[2,2],[2,2]])],[],[]]\n",
    "#print(polygon_list[0][0])\n",
    "\n",
    "new_img, new_poly = img_mask_rescale(imgs[0], np.array([]), 300, 200)\n",
    "new_poly = [[[],[]],[]]\n",
    "not new_poly == True\n",
    "#s = np.array([[],[]],[])\n",
    "#s.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "coordinate-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json_to_dict()\n",
    "test_show_img_and_mask()\n",
    "test_json_to_arrs()\n",
    "test_show_img_and_mask()\n",
    "test_polygon_arr_to_list()\n",
    "test_img_mask_rescale()\n",
    "test_to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "respected-nepal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary, imgs, polygon_list = json_to_dict(\"test_data/test_json/\", 200, 500)\n",
    "img, poly_for_single_img = json_to_arrs(\"test_data/test_json/test_json1.json\")\n",
    "#print(len(poly_for_single_img[0][0]))\n",
    "len(poly_for_single_img[0])\n",
    "#print(img.shape)\n",
    "#print(imgs[0].shape)\n",
    "#print(polygon_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "basic-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dictionary_fuction_for_detectron2(directory, img_height, img_width):\n",
    "    \"\"\"\n",
    "    This function converts the output of the main wrapper function\n",
    "    to the format required by Detectron2.\n",
    "    \"\"\"\n",
    "    dictionary, imgs, polygon_list = json_to_dict(directory, img_height, img_width)\n",
    "    return dictionary\n",
    "\n",
    "def show_img_and_mask(imgs,polygon_list):\n",
    "    \"\"\"\n",
    "    This function show the images and annotated masks\n",
    "         for the training dataset.\n",
    "    Input:\n",
    "        - list of nd array images\n",
    "        - list of polygon mask vertex coordinates\n",
    "    Output:\n",
    "        - Inline plot with images and masks\n",
    "    \"\"\"\n",
    "    mask = []\n",
    "    for img_num,polygon in enumerate(polygon_list):\n",
    "        plt.figure()\n",
    "        plt.imshow(imgs[img_num],alpha=1)\n",
    "        for mask_num,item in enumerate(polygon):\n",
    "            poly = item.tolist()\n",
    "            poly.append(item[-1].tolist())\n",
    "            x, y = zip(*poly)\n",
    "            mask.append(plt.fill(x,y,alpha=0.5,color=\"r\"))\n",
    "    for index,item in enumerate(mask):\n",
    "        plt.show(mask[index])\n",
    "        \n",
    "def json_to_arrs(json_file):\n",
    "    \"\"\"\n",
    "    Load a single image and its corresponding polygon masks from a jsonfile\n",
    "    Output the images as an np array and a the polygon masks as a list of\n",
    "    np arrays\n",
    "\n",
    "    Inputs:\n",
    "        - json_file: a json file that contains the image B64 format and\n",
    "                     the coordinates of the vertices of the polygon masks\n",
    "    Outputs:\n",
    "        - img: np array of the image\n",
    "        - poly_for_single_img: a list of np arrays, each represent one mask\n",
    "    \"\"\"\n",
    "    # Load data from json\n",
    "    data = json.load(open(json_file))\n",
    "    # Append images to a list of nd arrays\n",
    "    img_data = data.get(\"imageData\")\n",
    "    img = labelme.utils.img_b64_to_arr(img_data) # load image to np array\n",
    "    # Append mask to a list of polygons\n",
    "    poly = data.get(\"shapes\")\n",
    "    poly_for_single_img = []\n",
    "    for polyitem in poly:\n",
    "        polygon = np.array(polyitem.get(\"points\"))\n",
    "        polygon = np.reshape(polygon,(len(polygon),2))\n",
    "        poly_for_single_img.append(polygon)\n",
    "\n",
    "    return img, poly_for_single_img\n",
    "\n",
    "def polygon_arr_to_list(polygons):\n",
    "    \"\"\"\n",
    "    This funtion converts the a list of polygons for single image to \n",
    "    Detectron2 accpeted format and find the bounding boxes\n",
    "    Inputs:\n",
    "        - polygons: a list of np arrays that contains masks for a single image\n",
    "    Outputs:\n",
    "        - reshaped_polys: \n",
    "        - bb_boxes: coordinates of the bounding boxes of the masks\n",
    "    \"\"\"\n",
    "    reshaped_polys = []\n",
    "    bb_boxes =[]\n",
    "    for ind, polygon in enumerate(polygons):\n",
    "        reshaped_poly = polygon.reshape(1,polygon.shape[0]*polygon.shape[1]).tolist()[0]            \n",
    "        # [min_x, min_y, max_x, max_y]\n",
    "        bb_box = [np.min(reshaped_poly[0::2]),\n",
    "                np.min(reshaped_poly[1::2]),\n",
    "                np.max(reshaped_poly[0::2]),\n",
    "                np.max(reshaped_poly[1::2])]\n",
    "        reshaped_polys.append(reshaped_poly)\n",
    "        bb_boxes.append(bb_box)\n",
    "    return reshaped_polys, bb_boxes\n",
    "\n",
    "def img_mask_rescale(img, polygons, height, width):\n",
    "    \"\"\"\n",
    "    Rescale np array image and masks to designated height and width.\n",
    "    Return new img as np array, new maks as a list of np array\n",
    "    \"\"\"\n",
    "    scale = T.ScaleTransform(np.shape(img)[0],np.shape(img)[1], height, width)\n",
    "    new_img = scale.apply_image(img, \"bilinear\")\n",
    "    new_poly = scale.apply_polygons(polygons)\n",
    "    return new_img, new_poly\n",
    "\n",
    "def to_dict(path,jsonfile,img_num,height,width,reshaped_polygon_list, bb_box_list):\n",
    "    \"\"\"\n",
    "    Save all information into detectron2 dictionary\n",
    "    \"\"\"\n",
    "    filename = os.path.splitext(jsonfile)[0]\n",
    "    new_filename = filename+\".png\" # create new json filename\n",
    "    single_img_dict = {}\n",
    "    single_img_dict[\"file_name\"] = new_filename\n",
    "    single_img_dict[\"image_id\"] = img_num\n",
    "    single_img_dict[\"height\"] = height \n",
    "    single_img_dict[\"width\"] = width\n",
    "    \n",
    "    # Initiate list of dict [{instance1},{instance2},{instance3}}]]\n",
    "    # Each dict corresponds to annotations of one instance in this image\n",
    "    objs = []            \n",
    "    for instance,mask in enumerate(reshaped_polygon_list):\n",
    "        anno = {}\n",
    "        # Record segmentation as list[list[float]] as required by Detectron2\n",
    "        # Each list[float] is one instance\n",
    "        # in the format of [x1, y1, ..., xn, yn] (in unit of pixels).\n",
    "        anno[\"segmentation\"] = [reshaped_polygon_list[instance]]\n",
    "        # Record mask bounding box\n",
    "        anno[\"bbox\"] = bb_box_list[instance] # Bounding box\n",
    "        anno[\"bbox_mode\"] = BoxMode.XYXY_ABS # Type of bounding box\n",
    "        # Record category label: there is only one category, so always 0\n",
    "        anno[\"category_id\"] = 0 \n",
    "        objs.append(anno)\n",
    "    single_img_dict[\"annotations\"] = objs # list of dict [{instance1},{instance2},{instance3}}]]\n",
    "    return single_img_dict # {image1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-panama",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
