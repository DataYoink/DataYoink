{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "differential-highlight",
   "metadata": {},
   "source": [
    "### Inspect and Clean up the Dataset\n",
    "Procedures follow the example on the Mask_RCNN GitHub Page: https://github.com/matterport/Mask_RCNN/blob/master/samples/balloon/inspect_balloon_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expensive-region",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mrcnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-679a829e1fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Import Mask RCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# To find local version of the library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmrcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mrcnn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import math\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.lines as lines\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "\"\"\"\n",
    "Need to Install mrcnn and detectron2\n",
    "\"\"\"\n",
    "\n",
    "import detectron2\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from samples.balloon import balloon\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-viking",
   "metadata": {},
   "source": [
    "### Image Resize with Detectron\n",
    "This is a built-in function in Detectron that can be used to resize the dataset. This resize likely does not use padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2.data.transforms as T\n",
    "\n",
    "# Set dataloader to resize\n",
    "from detectron2.data import DatasetMapper   # the default mapper\n",
    "dataloader = build_detection_train_loader(cfg,\n",
    "   mapper=DatasetMapper(cfg, is_train=True, augmentations=[\n",
    "      T.Resize((800, 800))\n",
    "   ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-deficit",
   "metadata": {},
   "source": [
    "### Image Resize with MRCNN\n",
    "This piece of code resize the image and the mask altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load random image and mask.\n",
    "image_id = np.random.choice(dataset.image_ids, 1)[0]\n",
    "image = dataset.load_image(image_id)\n",
    "mask, class_ids = dataset.load_mask(image_id)\n",
    "original_shape = image.shape\n",
    "# Resize\n",
    "image, window, scale, padding, _ = utils.resize_image(\n",
    "    image, \n",
    "    min_dim=config.IMAGE_MIN_DIM, \n",
    "    max_dim=config.IMAGE_MAX_DIM,\n",
    "    mode=config.IMAGE_RESIZE_MODE)\n",
    "mask = utils.resize_mask(mask, scale, padding)\n",
    "# Compute Bounding box\n",
    "bbox = utils.extract_bboxes(mask)\n",
    "\n",
    "# Display image and additional stats\n",
    "print(\"image_id: \", image_id, dataset.image_reference(image_id))\n",
    "print(\"Original shape: \", original_shape)\n",
    "log(\"image\", image)\n",
    "log(\"mask\", mask)\n",
    "log(\"class_ids\", class_ids)\n",
    "log(\"bbox\", bbox)\n",
    "# Display image and instances\n",
    "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-corpus",
   "metadata": {},
   "source": [
    "### Convert Our Data to Dictionary and Register to Detectron2\n",
    "Procedrues follow the tutorial: https://wendeehsu.medium.com/instance-segmentation-with-detectron2-127fbe01b20b <br/>\n",
    "We first convert our .json annotation files to Detectron2 dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts(img_dir):\n",
    "    \"\"\"\n",
    "    This function takes in our annotated json file and convert it to \n",
    "    the dictionary file type that is accepted by Detectron2.\n",
    "    \"\"\"\n",
    "    json_file = os.path.join(img_dir, \"via_export_json.json\") ### Need to set out own directory and json filename here\n",
    "    \n",
    "    with open(json_file) as f:\n",
    "        imgs_anns = json.load(f)\n",
    "    dataset_dicts = []\n",
    "    for idx, v in enumerate(imgs_anns.values()):\n",
    "        record = {}\n",
    "        \n",
    "        filename = os.path.join(img_dir, v[\"filename\"])\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "        \n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "      \n",
    "        annos = v[\"regions\"]\n",
    "        objs = []\n",
    "        for anno in annos:\n",
    "            anno = anno[\"shape_attributes\"]\n",
    "            px = anno[\"all_points_x\"]\n",
    "            py = anno[\"all_points_y\"]\n",
    "            poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            obj = {\n",
    "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                \"segmentation\": [poly],\n",
    "                \"category_id\": 0,\n",
    "                \"iscrowd\": 0\n",
    "                }\n",
    "            objs.append(obj)\n",
    "            print(objs)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-nutrition",
   "metadata": {},
   "source": [
    "Then Register the voltage discharge curve and dqdv curve dataset with Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "path = \"/content/drive/.../wendee/images\" ##### Need to set the path to our own image directory\n",
    "\n",
    "for file in [\"training_data_discharge_curve\", \"testing_data_discharge_curve\"]:\n",
    "    DatasetCatalog.register(\"voltage_discharge_curve_\" + file, lambda file=file: get_dicts(path + \"/\" +  file))\n",
    "    MetadataCatalog.get(\"voltage_discharge_curve_\" + d).set(thing_classes=[\"DischargeCurve\"])\n",
    "\n",
    "for file in [\"training_data_dqdv_curve\", \"testing_data_dqdv_curve\"]:\n",
    "    DatasetCatalog.register(\"dqdv_curve_\" + file, lambda file=file: get_dicts(path + \"/\" +  file))\n",
    "    MetadataCatalog.get(\"dqdv_curve_\" + d).set(thing_classes=[\"DqdvCurve\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-rocket",
   "metadata": {},
   "source": [
    "Visualize the data to see if it's registered okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intelligent-error",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bffe170851e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mango_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "dataset_dicts = get_dicts(path + \"training_data_discharge_curve\")\n",
    "for data in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(data[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=MetadataCatalog.get(\"voltage_discharge_curve_training_data_discharge_curve\"), scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(data)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-livestock",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
